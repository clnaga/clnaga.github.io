<!DOCTYPE html>
<html>
<head>
  <title>梯度下降优化算法总览-EmiyaCC Blog</title>
  <meta charset="utf-8" />
  <meta http-equiv="content-language" content="zh-CN" />
  <meta name="theme-color" content="#ffffff" />
  <meta name="supported-color-schemes" content="light dark">
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta name="applicable-device" content="pc,mobile">
  <meta name="google-site-verification" content="ckhUaoa05QCmWoE1FafzTBcqYI4yBOy-UJKopXDS18M" />
  <meta name="author" content="EmiyaCC" />
  <meta name="description" content="梯度下降优化算法总览"/>
  <meta name="keywords" content="EmiyaCC,梯度下降,深度学习"/>
  <link rel="icon" href="/static/img/favicon.ico" />
  <link rel="apple-touch-icon" href="/static/img/logo.png" />
  <link rel="stylesheet" href="/static/css/common.css?t=20210622203029">
  <link rel="stylesheet" href="/static/css/theme-dark.css?t=20210622203029">
  <link rel="stylesheet" href="/static/css/post.css?t=20210622203029">
  <link rel="stylesheet" href="/static/css/code-dark.css?t=20210622203029">
  <link rel="stylesheet" href="/static/css/code-light.css?t=20210622203029">
  <script>
    window.blog = {
      baseurl:"",
      buildAt:"20210622203029",
      darkTheme: false,
      setDarkTheme: function (dark) {
        this.darkTheme = Boolean(dark);
        document.documentElement.className = this.darkTheme ? 'dark': '';
        document.querySelector('meta[name=theme-color]').setAttribute('content', this.darkTheme ? '#2D2E32': '#FFFFFF');
      }
    }
    if (sessionStorage.darkTheme !== undefined) {
      blog.setDarkTheme(sessionStorage.darkTheme === 'true'); // 记忆值，单个窗口内有效
    } else {
      blog.setDarkTheme(window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches); // 跟随系统
    }
    if (window.matchMedia) {
      var media = window.matchMedia('(prefers-color-scheme: dark)');
      media.addListener(function (ev) {
        blog.setDarkTheme(ev.currentTarget.matches);
        sessionStorage.removeItem('darkTheme');
      });
    }
  </script>
</head>
<body ondragstart="return false;">
<header class="header">
  <img class="logo" src="/static/img/logo.jpg" alt="logo"/>
  <nav class="menu">
    <a href="/" class="hover-underline">首页</a>
    <a href="/pages/categories.html" class="hover-underline">归类</a>
    <a href="/pages/search.html" class="hover-underline">搜索</a>
    <a href="/pages/links.html" class="hover-underline">友链</a>
    <a href="/pages/about.html" class="hover-underline">关于</a>
    </nav>
</header>
<div class="page page-post">
  <h1 class="title" id="梯度下降优化算法总览">梯度下降优化算法总览</h1>
  
  <div class="subtitle">EmiyaCC 于 2021-03-03 发布</div>
  
  <div class="post">
    <div class="toc">
      <ul><li><a href="#梯度下降优化算法总览"><a href="https://ruder.io/optimizing-gradient-descent/index.html#additionalstrategiesforoptimizingsgd">梯度下降优化算法总览</a></a><ul><li><a href="#梯度下降种类">梯度下降种类</a><ul><li><a href="#bgd-批次梯度下降">BGD （批次梯度下降）</a></li><li><a href="#sgd-随机梯度下降">SGD （随机梯度下降）</a></li><li><a href="#mbgd-小批次梯度下降">MBGD （小批次梯度下降）</a></li><li><a href="#挑战">挑战</a></li></ul></li><li><a href="#梯度下降优化算法">梯度下降优化算法</a><ul><li><a href="#momentum">Momentum</a></li><li><a href="#nag-nesterov-accelerated-gradient">NAG (Nesterov Accelerated Gradient)</a></li><li><a href="#adagrad">Adagrad</a></li><li><a href="#adadelta">Adadelta</a></li><li><a href="#rmsprop">RMSprop</a></li><li><a href="#adam-adaptive-moment-estimation">Adam (Adaptive Moment Estimation)</a></li><li><a href="#adamax">AdaMax</a></li><li><a href="#nadam-nesterov-accelerated-adaptive-moment-estimation">Nadam (Nesterov-accelerated Adaptive Moment Estimation)</a></li><li><a href="#amsgrad">AMSGrad</a></li><li><a href="#使用哪个优化算法">使用哪个优化算法？</a></li></ul></li><li><a href="#优化-sgd-的其他策略">优化 SGD 的其他策略</a><ul><li><a href="#shuffling-和课程学习">Shuffling 和课程学习</a></li><li><a href="#batch-normalization">Batch normalization</a></li><li><a href="#early-stopping">Early stopping</a></li><li><a href="#gradient-noise">Gradient noise</a></li></ul></li><li><a href="#ref">Ref</a></li></ul></li></ul>

    </div>
    <h1 id="梯度下降优化算法总览"><a href="https://ruder.io/optimizing-gradient-descent/index.html#additionalstrategiesforoptimizingsgd">梯度下降优化算法总览</a></h1>

<blockquote>
  <p><strong>优化</strong>指的是改变 $\theta$ 以最小化或最大化某个函数 $J(\theta)$ 的任务。我们通常以最小化 $J(\theta)$ 指代大多数最优化问题。最大化可经由最小化算法最小化 $-J(\theta)$ 来实现。我们把要最小化或最大化的函数称为目标函数（objective function）或准则（criterion）。当我们对其进行最小化时，我们也把它称为代价函数（cost function）、 损失函数（loss function）或误差函数（error function）。【花书】</p>

  <p>梯度下降是一种优化算法，其中，学习率 $\eta$ 决定了我们到达（局部）最小值的步长</p>
</blockquote>

<h2 id="梯度下降种类">梯度下降种类</h2>

<blockquote>
  <p>梯度下降根据计算目标函数的梯度所用的数据量不同，大体分为三类。根据数据量，我们可以在参数更新的准确性和执行更新所需的时间之间进行权衡</p>
</blockquote>

<h3 id="bgd-批次梯度下降">BGD （批次梯度下降）</h3>

<blockquote>
  <p>公式：
<script type="math/tex">\theta = \theta - \eta \cdot \nabla_\theta J(\theta)</script>
由于在每一次更新中，我们都需要计算整个数据集的梯度，所以 BGD 可能会非常缓慢，并且内存装不下的数据集很棘手。不可在线学习（需要一次得到整个数据集）。</p>

  <p>然后，我们以与梯度相反的方向更新参数，学习率决定了我们执行的更新量。对于凸面误差曲面，批梯度下降可以保证收敛到全局最小值，对于非凸面曲面，可以保证收敛到局部最小值。</p>
</blockquote>

<h3 id="sgd-随机梯度下降">SGD （随机梯度下降）</h3>

<blockquote>
  <p>相较与 BGD，SGD 对每个训练样本 $x^{(i)}$ 和标签 $y^{(i)}$ 都做参数更新。【由于是做 BN，都是一个 batch 一个 batch 的算，计算一个 batch 里的所有样本】</p>

  <p>公式：
<script type="math/tex">\theta = \theta - \eta \cdot \nabla_\theta J(\theta;x^{(i)};y^{(i)})</script></p>
</blockquote>

<blockquote>
  <p>BGD 对于大型数据集会有冗余计算，因为他会在每个参数更新之前重新计算相似样本的梯度。</p>

  <p>SGD 通过一次执行一次更新的方式来消除这种冗余，因此它通常速度很快，也可以用于在线学习。SGD 频繁执行更新且变化很大，这导致目标函数如下图所示，会剧烈波动</p>

  <p><img src="sgd_fluctuation.png" alt="SGD fluctuation" style="zoom: 50%;" /></p>

  <p>当 BGD 收敛到参数的盆地的最小值时，SGD的波动一方面使它跳到新的并可能是更好的局部最小值，但另一方面，这也导致 SGD 会错过最低值（overshooting），使得 SGD 收敛到最小值会很困难。但是，已经表明，当我们缓慢降低学习率时，SGD 会显示与 BGD 相同的收敛行为，几乎可以肯定地，对于非凸优化和凸优化，它们分别收敛到局部或全局最小值。</p>
</blockquote>

<h3 id="mbgd-小批次梯度下降">MBGD （小批次梯度下降）</h3>

<blockquote>
  <p>MBGD 是 BGD 和 SGD 的折中，每次更新小批量中的 $n$ 个样本的梯度。</p>

  <p>公式：
<script type="math/tex">\theta_{t+1} = \theta_t - \eta \cdot \nabla_\theta J(\theta;x^{(i:i+n)};y^{(i:i+n)})</script></p>
</blockquote>

<blockquote>
  <p>这样做 1）减少了参数更新的方差，这可以使收敛更加稳定， 2）可以利用深度学习库的高度优化的矩阵优化功能，快速的计算一个小批次数据的梯度。</p>

  <p>常见的小批次大小设置在 50 到 256 之间（随不同应用变化），训练神经网络时，通常选择小批量梯度下降算法，而当使用小批量时，通常也使用术语SGD。</p>
</blockquote>

<h3 id="挑战">挑战</h3>

<blockquote>
  <p>但是，MBGD 不能保证良好的收敛性，但是存在一些需要解决的问题：</p>

  <ul>
    <li>选择合适的学习率十分困难，学习率太小会导致收敛过于缓慢，学习率太大导致不容易收敛，并导致损失函数在最小值附近波动甚至发散；</li>
    <li>学习率 schedules 可以在训练过程中调整学习率比如说退火算法，即根据预定义的时间表或在各个时期之间的目标变化降到阈值以下时降低学习率。
但是，这些计划和阈值必须预先定义，因此无法适应数据集的特征；</li>
    <li>此外，所有参数更新都使用同一学习率。如果我们的数据稀疏并且特征有非常不同的频率，那么我们可能不想所有的参数都更新相同的程度，而是对较少出现的特征进行更大的更更新；</li>
    <li>最小化神经网络常见的高度非凸误差函数的另一个关键挑战是避免陷入其众多次优局部最小值中。Dauphin et al. 认为收敛困难实际上不是由局部极小值引起的，而是由鞍点（即一维向上倾斜而另一维向下倾斜的点）引起的。这些鞍点通常被相同误差的平稳段包围，这使得SGD很难逃脱，因为在所有维度上梯度都接近于零。</li>
  </ul>
</blockquote>

<h2 id="梯度下降优化算法">梯度下降优化算法</h2>

<h3 id="momentum">Momentum</h3>

<blockquote>
  <p>SGD 很难在沟壑中前进，即在一个维度上，曲面的弯曲比另一个维度要陡得多，这在局部最优情况下很常见。在这种情况下 SGD 会在峡谷得山坡山震荡，犹豫不决得向局部最优方向前进，如下图。</p>

  <p><img src="without_momentum.gif" alt="SGD without momentum" style="zoom:50%;" /></p>

  <p>Momentum 可以在相关方向加速 SGD 并抑制震荡，如下图。</p>

  <p><img src="with_momentum.gif" alt="SGD with momentum" style="zoom:50%;" /></p>

  <p>通过将过去时间步长得更新向量的分数 $\gamma$ 与当前更新向量相加来实现。</p>
</blockquote>

<blockquote>
  <p>公式：
<script type="math/tex">v_t = \gamma v_{t-1} + \eta \nabla_\theta J(\theta) \\
\theta_{t+1} = \theta_t - v_t</script>
其中，动量项 $\gamma$ 通常设为 0.9。<strong>需要注意的是一些实现交换方程式中的符号，如下</strong>：
<script type="math/tex">v_t = \gamma v_{t-1} + \nabla_\theta J(\theta) \\
\theta_{t+1} = \theta_t - \eta v_t \\</script>
其他实现见 <a href="https://jlmelville.github.io/mize/nesterov.html">James Melville</a></p>
</blockquote>

<blockquote>
  <p>比如，我们将球推下山坡，球在下坡时滚动时会积累动量，在途中速度会越来越快（如果存在空气阻力，即 $\gamma$ &lt;1，直到达到最终速度）。
我们的参数更新也发生了同样的事情：动量项对于梯度指向相同方向的维增加，而对于梯度改变方向的维减少动量。结果，我们获得了更快的收敛并减少了振荡。</p>
</blockquote>

<h3 id="nag-nesterov-accelerated-gradient">NAG (Nesterov Accelerated Gradient)</h3>

<blockquote>
  <p>然后令人不满的是让一个球从山上滚下来，会盲目的随着斜坡滚，我们希望这个球具有要往何处的概念，这样当山坡再次变高之前知道它应该减速。</p>
</blockquote>

<blockquote>
  <p>NAG 完成了这种预见的功能【花书中解释是相当于加了一个校正向量】，我们先通过计算 $\theta - \gamma v_{t-1}$ 计算出参数下一个位置的近似值（离完整更新还缺少梯度），通过计算不是现在位置的参数 $\theta$ 而是未来的位置参数 $\theta$ 的梯度，从而达到有效率的前看（look ahead）。公式为：
<script type="math/tex">v_t = \gamma v_{t-1} + \eta \nabla_\theta J(\theta_{t-1} - \gamma v_{t-1}) \\
\theta_t = \theta_{t-1} - v_t</script>
其中，动量项 $\gamma$ 通常设为 0.9</p>
</blockquote>

<blockquote>
  <p>Momentum 首先计算当前梯度（图中的蓝色小矢量），然后在更新的累积梯度（蓝色矢量）的方向上发生较大的跃迁，而 NAG 首先在先前的累积梯度的方向上进行较大的跃迁（棕色矢量），测量梯度，然后进行校正（红色矢量），从而完成NAG更新（绿色矢量）。
这种预期的更新可防止我们过快地进行，并导致响应速度增加，从而显着提高了RNN在许多任务上的性能。</p>

  <p><img src="nesterov_update_vector.png" alt="SGD fluctuation" style="zoom: 50%;" /></p>

  <p>现在，我们能够使更新适应误差函数的斜率并依次提高SGD，我们还希望使更新适应每个单独的参数，以根据其重要性执行更大或更小的更新。</p>
</blockquote>

<blockquote>
  <p>另一种角度解释，这里使用另一种 NAG 的实现方程：
<script type="math/tex">v_{t+1} = \gamma v_t + g(\theta_t - \eta \gamma v_t) \\
\theta_{t + 1} = \theta_t - \eta v_{t + 1}</script>
对 NAG 原来的更新公式进行变换，得到这样的等效形式：
<script type="math/tex">v_{t+1} = \gamma v_t + g(\theta_t) + \gamma [g(\theta_t) - g(\theta_{t-1})] \\
\theta_{t+1} = \theta_t - \eta v_{t+1}</script>
可以看到这个 NAG 的等效形式与 Momentum 的区别在于，本次更新方向多加了一个 $\gamma [g(\theta_t) - g(\theta_{t-1})]$，它的直观含义就很明显了：如果这次的梯度比上次的梯度变大了，那么有理由相信它会继续变大下去，那我就把预计要增大的部分提前加进来；如果相比上次变小了，也是类似的情况。这个多加上去的项不就是在近似目标函数的二阶导！<strong>所以NAG本质上是多考虑了目标函数的二阶导信息，怪不得可以加速收敛了！其实所谓“往前看”的说法，在牛顿法这样的二阶方法中也是经常提到的，比喻起来是说“往前看”，数学本质上则是利用了目标函数的二阶导信息。</strong></p>

  <p>等价推导，NAG原始公式：
<script type="math/tex">% <![CDATA[
\begin{align}
& v_{t+1} = \gamma v_t + g(\theta_t - \eta \gamma v_t) \\ 
& \theta_{t + 1} = \theta_t - \eta v_{t + 1} \\
\end{align} %]]></script>
两边同时减 $\eta \gamma v_{t+1}$ 有：
<script type="math/tex">% <![CDATA[
\begin{align}
\theta_{t+1} - \eta \gamma v_{t+1} &= \theta_t - \eta v_{t+1} - \eta \gamma v_{t+1} \\
& = \theta_t - \eta (1+\gamma)v_{t+1} \\ 
& = \theta_t - \eta (1+\gamma)(\gamma v_t + g(\theta_t-\eta\gamma v_t)) \\
& = \theta_t - \eta \gamma v_t - \eta \gamma^2 v_t - \eta (1+\gamma) g(\theta_t - \eta \gamma v_t)
\end{align} %]]></script>
可令：
<script type="math/tex">% <![CDATA[
\begin{align}
 \hat \theta_{t+1} &\triangleq \theta_{t+1} - \eta \gamma v_{t+1} \\
 \hat \theta_t &\triangleq \theta_t - \eta \gamma v_t \\
 \hat v_{t+1} &\triangleq \gamma^2 v_t + (1+\gamma) g(\theta_t - \eta \gamma v_t) \\
 & = \gamma^2 v_t + (1+\gamma) g(\hat \theta_t) 
\end{align} %]]></script>
代入上式有：
<script type="math/tex">\hat \theta_{t+1} = \hat \theta_t - \eta \hat v_{t+1}</script>
对 $\hat v_{t+1}$ 展开可得：
<script type="math/tex">% <![CDATA[
\begin{align}
  \hat v_{t+1} &= \gamma^2 v_t + (1+\gamma) g(\hat \theta_t)  \\ 
  &= (1+\gamma) g(\hat \theta_t) + \gamma^2(\gamma v_{t+1} + g(\theta_{t-1} - \eta \gamma v_{t-1}))
  &=(1+\gamma) g(\hat \theta_t) + \gamma^2(\gamma v_{t+1} + g(\hat \theta_{t-1})) \\
  & ... \\
  &= (1+\gamma)g(\hat \theta_t) + \gamma^2g(\hat \theta_{t-1}) + ...
 \end{align} %]]></script>
所以 $\hat v_{t+1} - \gamma \hat v_t$ 有：
<script type="math/tex">% <![CDATA[
\begin{align}
 \hat v_{t+1} - \gamma \hat v_t &= [(1+\gamma)g(\hat \theta_t) + \gamma^2g(\hat \theta_{t-1}) + ...] - [(1+\gamma)g(\hat \theta_{t-1}) + \gamma^2g(\hat \theta_{t-2}) + ...] \\
 &= g(\hat \theta_t) + \gamma (g(\hat \theta_t) - g(\hat \theta_{t-1})) \\
  \hat v_{t+1} &=  \gamma \hat v_t + g(\hat \theta_t) + \gamma (g(\hat \theta_t) - g(\hat \theta_{t-1}))
\end{align} %]]></script>
证明成功，原作者太强了。</p>

  <blockquote>
    <p>ref: https://zhuanlan.zhihu.com/p/22810533</p>
  </blockquote>
</blockquote>

<h3 id="adagrad">Adagrad</h3>

<blockquote>
  <p>Adagrad 是一种基于梯度的优化算法，它可以使学习率适应参数，对与频繁出现的特征相关的参数执行较小的更新（即低学习率），对与不频繁出现的特征相关的参数执行较大的更新（即高学习率）。<strong>因此非常适合处理稀疏数据</strong></p>
</blockquote>

<blockquote>
  <p>之前，我们一次对所有的参数 $\theta$ 进行更新，因为每个参数 $\theta_i$ 使用相同的学习率$\eta$ 。因为 Adagrad 在每个时间步长 $t$ 对每个参数 $\theta_i$ 使用不同的学习率，因此首先对显示 Adagrad 的每个参数更新，再将其向量化。为了简便起见，使用 $g_t$ 表示时间步长 $t$ 处的梯度，$g_{t,i}$ 表示时间步长 $t$ 参数 $\theta_i$ 的目标函数的偏导数：
<script type="math/tex">g_{t,i} = \nabla_\theta J(\theta_{t,i})</script></p>
</blockquote>

<blockquote>
  <p>在 SGD 中，每个时间步长 $t$ 处每个参数 $\theta$ 的更新为：</p>

  <p>在 Adagrad 中，基于对 $\theta_i$ 计算的过去梯度，针对每个参数 $\theta_i$ 在每个时间步长 $t$ 修改通用学习率 $\eta$：
<script type="math/tex">\theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}} \cdot g_{t,i}</script>
其中，$G_t \in \mathbb{R}^{d \times d}$，这是个对角矩阵，其中每个对角元素 $i,i$ 是在时间步长 $t$ 处 $\theta_i$ 的梯度的平方和，$\epsilon$ 是一个平滑项（smoothing term），避免分母为0（通常设置为 $1e^{-8}$ 量级）。<strong>有趣的是，如果没有平方根运算，该算法的性能将大大降低</strong></p>

  <p>由于 $G_t$ 包括过去的沿对角线的所有参数 $\theta$ 梯度的平方和，所有我们可以通过对 $G_t$ 和 $g_t$ 之间做矩阵向量点积 $\odot$ 来向量化实现：
<script type="math/tex">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot g_t</script></p>
</blockquote>

<blockquote>
  <p>Adagrad 的主要好处之一是，它无需手动调整学习率，大多数实现使用默认的 0.01</p>

  <p>Adagrad 的主要弱点是分母中平方梯度的累加：由于每个加法项都是正数，所以累加和在训练期间不断增长。反过来，这导致学习率下降，并最终变得无限小，这时该算法不再能够获取其他知识。以下算法旨在解决此缺陷。</p>
</blockquote>

<h3 id="adadelta">Adadelta</h3>

<blockquote>
  <p>Adadelta 是 Adagrad 的扩展，旨在降低其激进的，单调降低的学习率。Adadelta 不会累计所有过去的平方梯度，而是将累计过去的梯度的窗口限制为某个固定大小 $w$。代替无效的存储过去平方梯度（past squared gradients），将梯度之和递归定义为所有过去梯度梯度的衰减平均值（decaying average），在时间步长 $t$ 处的移动平均值（running average）$E[g^2]_t$ 仅取决与先前的平均值和当前梯度（分数 $\gamma$ 相当于 Momentum 里的动量项）：
<script type="math/tex">E[g^2]_t = \gamma E[g^2]_{t-1} + (1 - \gamma) g_t^2</script>
我们将 $\gamma$ 设置与动量项相似的值，约为 0.9。</p>
</blockquote>

<blockquote>
  <p>为了清晰起见，先根据参数更新向量 $\Delta \theta_t$ 来重写朴素 SGD：
<script type="math/tex">\Delta \theta_t = - \eta \cdot g_{t,i} \\
\theta_{t+1} = \theta_t + \Delta \theta_t</script>
因此，我们先前推导的 Adagrad 的参数更新向量采用以下形式：
<script type="math/tex">\Delta \theta_t = - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot g_t</script>
现在我们用过去梯度梯度上的衰减平均值（decaying average）代替对角矩阵 $G_t$：
<script type="math/tex">\Delta \theta_t = - \frac{\eta}{\sqrt{E[g^2]_t} + \epsilon} g_t</script>
由于分母只是梯度的均方差（RMS）误差准组，可以替换简写准则：
<script type="math/tex">\Delta \theta_t = - \frac{\eta}{RMS[g]_t} g_t</script>
作者注意到，此处更新的单位（以及 SGD，Momentum 或 Adagrad 中的单位）不匹配，即，更新应具有与参数相同的假设单位。为了实现这一点，他们首先定义了另一个指数衰减的平均值，这次不是平方梯度而是平方参数更新：
<script type="math/tex">RMS[\Delta \theta]_t = \sqrt{E[\Delta \theta^2]_t + \epsilon}</script>
由于 $RMS[\Delta \theta]<em>t$ 是未知的，因此我们使用参数更新的 $RMS$ 对其进行近似，直到上一个时间步长为止。最终，用 $RMS[\Delta \theta]</em>{t-1}$ 代替先前的更新规则中的学习率 $\eta$，得出 Adadelta 更新规则：
<script type="math/tex">\Delta \theta_t = - \frac{RMS[\Delta \theta]_{t-1}}{RMS[g]_t} g_t \\
\theta_{t+1} = \theta_t + \Delta \theta_t</script>
所以使用 Adadelta，我们甚至不需要设置默认的学习率，因为它已从更新规则中删除。</p>
</blockquote>

<h3 id="rmsprop">RMSprop</h3>

<blockquote>
  <p>RMSprop 是由 Geoff Hinton 在他的 <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">Coursera课的第6e</a> 讲中提出的未公开的自适应学习率方法。</p>
</blockquote>

<blockquote>
  <p>RMSprop 和 Adadelta 大约在同一时间提出，这是因为需要解决 Adagrad 的学习率急剧下降的问题。 
RMSprop 实际上与我们上面得出的 Adadelta 的第一个更新向量相同：
<script type="math/tex">E[g^2]_t = 0.9 E[g^2]_{t-1} + 0.1 g_t^2 \\
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t</script>
RMSprop 也将学习率除以平方梯度的指数衰减平均值（exponentially decaying average）。Hinton 建议将 $\gamma$ 设置为 0.9，学习率 $\eta$ 的默认值是 0.001。</p>
</blockquote>

<h3 id="adam-adaptive-moment-estimation">Adam (Adaptive Moment Estimation)</h3>

<blockquote>
  <p>Adam 是另一种计算每个参数的自适应学习率的方法。<strong>等价 RMSprop + Momentum</strong></p>

  <p>除了存储像 Adadelta 和 RMSprop 这样的过去平方梯度 $v_t$ 的指数衰减平均值之外，Adam 还保留了过去梯度 $m_t$ 的指数衰减平均值，类似于 Momentum。Momentum 以看作是一个顺着斜坡滑下的球，而 Adam 的行为就像是一个带有摩擦的沉重的球，因此，它更喜欢在误差表面上保持平坦的最小值。我们分别计算过去梯度 $m_t$ 和过去平方梯度 $v_t$ 的衰减平均值，如下所示：
<script type="math/tex">m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t \\
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2</script>
$m_t$ 和 $v_t$ 分别是梯度的第一矩（均值）和第二矩（无中心方差）的估计值。当 $m_t$ 和 $v_t$ 初始化为 0 的向量时，Adam 的作者观察到它们偏向零，尤其是在初始时间步长，衰减率较小时（即β1和β2接近1）。</p>

  <p>他们通过计算经过偏差校正的第一和第二矩估计值来抵消这些偏差：
<script type="math/tex">\hat m_t = \frac{m_t}{1 - \beta_1^t} \\
\hat v_t = \frac{v_t}{1 - \beta_2^t}</script>
然后，他们使用它们来更新参数，就像在 Adadelta 和 RMSprop 中所看到的那样，这将产生 Adam 更新规则：
<script type="math/tex">\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\hat v_t + \epsilon}} \hat m_t</script>
作者建议将 $\beta_1$ 的默认值设置为 0.9，将 $\beta_2$ 的默认值设置为 0.999，将 $\epsilon$ 的默认值设置为 $10^{-8}$。</p>
</blockquote>

<h3 id="adamax">AdaMax</h3>

<blockquote>
  <p>Adam 的更新规则中，$v_t$ 与过去梯度（通过 $v_{t-1}$）和当前梯度 $|g_t|^2$ 的 $l_2$ 范数成反比的缩放梯度：
<script type="math/tex">v_t = \beta_2 v_{t-1} + (1 - \beta_2) |g_t|^2</script>
我们可以将此更新推广到 $l_p$ 范数：
<script type="math/tex">v_t = \beta_2^p v_{t-1} + (1 - \beta_2^p) |g_t|^p</script>
大 $p$ 值的范数通常在数值上变得不稳定，这就是为什么 $l_1$ 和 $l_2$ 范数在实践中最常见的原因。但是，$l_\infty$ 通常也表现出稳定的行为。因此，作者提出了AdaMax，并证明具有 $l_\infty$ 的 $v_t$ 收敛到以下更稳定的值。为了避免与 Adam 混淆，我们使用 $u_t$ 表示无穷范数约束 $v_t$：
<script type="math/tex">% <![CDATA[
\begin{align}
  &u_t = \beta_2^\infty v_{t-1} + (1 - \beta_2^\infty) |g_t|^\infty \\
  &~~~~  = max(\beta_2 \cdot v_{t - 1}, |g_t|)
 \end{align} %]]></script>
然后就可以将 $u_t$ 代替 $\sqrt{v_t} + \epsilon$ 插入 Adam 的更新方程中，得到 AdaMax 的更新规则：
<script type="math/tex">\theta_{t+1} = \theta_t - \frac{\eta}{u_t} \hat m_t</script>
请注意，由于 $u_t$ 依赖于 $max$ 运算，因此不建议像 Adam 中的 $m_t$ 和 $v_t$ 那样偏向零，这就是为什么我们不需要计算 $u_t$ 的偏差校正的原因。默认值是 $\eta = 0.002, \beta_1 = 0.9, \beta_2 = 0.999$。</p>
</blockquote>

<h3 id="nadam-nesterov-accelerated-adaptive-moment-estimation">Nadam (Nesterov-accelerated Adaptive Moment Estimation)</h3>

<blockquote>
  <p>如之前所见，Adam 可以看作是 RMSprop 和 Momentum 的组合：RMSprop 贡献了过去平方梯度 $v_t$ 的指数衰减平均值，而 Momentum 贡献了过去梯度 $m_t$ 的指数衰减平均值。同时我们也看到 NAG 由于普通的 Momentum。</p>
</blockquote>

<blockquote>
  <p>因此，<strong>Nadam 结合了 Adam 和 NAG</strong>。为了将 NAG 合并到 Adam 中，我们需要修改其动量项 $m_t$。</p>

  <p>首先回顾 Momentum 的更新规则：
<script type="math/tex">g_t = \nabla_{\theta_t} J(\theta_t) \\
m_t = \gamma m_{t-1} + \eta g_t \\
\theta_{t+1} = \theta_t - m_t</script>
其中 $J$ 是我们的目标函数，$\gamma$ 是动量衰减项，$\eta$ 是我们的步长。将上面的第三个方程式扩展会得出：
<script type="math/tex">\theta_{t+1} = \theta_t - (\gamma m_{t-1} + \eta g_t)</script>
这再次证明了 Momentum 在前一个动量矢量的方向上迈出一步以及在当前梯度的方向上迈出一步。</p>

  <p>NAG 允许我们在计算梯度之前通过用动量步长更新参数来在梯度方向上执行更精确的步长。因此，我们只需要修改梯度 $g_t$ 即可得出 NAG：
<script type="math/tex">g_t = \nabla_{\theta_t} J(\theta_t - \gamma m_{t-1}) \\
m_t = \gamma m_{t-1} + \eta g_t \\
\theta_{t+1} = \theta_t - m_t</script>
Dozat 建议以以下方式修改 NAG：直接应用前瞻动量矢量（look-ahead momentum vector）来更新当前参数，而不是用两此 Momentum 步骤（一次用于更新梯度 $g_t$，第二次用于更新参数 $\theta_{t+1}$）
<script type="math/tex">g_t = \nabla_{\theta_t} J(\theta_t) \\
m_t = \gamma m_{t-1} + \eta g_t \\
\theta_{t+1} = \theta_t - (\gamma m_t + \eta g_t)</script>
注意到，我们不再像上面的 Momentum 更新规则的公式那样使用先前的动量矢量 $m_{t-1}$，而是现在使用当前的动量矢量 $m_t$ 向前看。为了将 Nesterov 动量添加到 Adam，我们可以类似地用当前动量矢量替换以前的动量矢量。
首先，回想一下 Adma 更新规则如下（注意，我们不需要修改 $\hat v_t$，所以此处省略 $\hat v_t$ 的更新公式）：
<script type="math/tex">m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t \\
\hat m_t = \frac{m_t}{1 - \beta_1^t} \\
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon} \hat m_t</script>
依次用 $\hat m_t$ 和 $m_t$ 的定义扩展第二个方程式，我们得到：
<script type="math/tex">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon} (\frac{\beta_1 m_{t-1}}{1 - \beta_1^t} +\frac{(1 - \beta_1) g_t}{1 - \beta_1^t})</script>
注意到，$\frac{\beta_1 m_{t-1}}{1 - \beta_1^t}$ 只是前一时间步长的动量矢量的偏差校正估计，因此，我们可以将其替换为 $m_{t-1}$：
<script type="math/tex">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon} (\beta_1 \hat m_{t-1} +\frac{(1 - \beta_1) g_t}{1 - \beta_1^t})</script>
为简单起见，我们忽略了分母为 $1 - \beta_1^t$ 而不是 $1 - \beta_1^{t-1}$，因为无论如何我们将在下一步中替换分母。该方程式再次看起来与我们上面扩展的 Momentum 更新规则非常相似。现在，我们可以像以前一样添加 Nesterov 动量，只需用当前动量矢量 $\hat m_{t-1}$ 的偏差校正后的估计值简单地替换前一个时间步 $\hat m_t$ 的该偏差校正后的估计值即可，Nadam 更新规则：
<script type="math/tex">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon} (\beta_1 \hat m_t +\frac{(1 - \beta_1) g_t}{1 - \beta_1^t})</script></p>
</blockquote>

<h3 id="amsgrad">AMSGrad</h3>

<blockquote>
  <p>由于自适应学习率方法已成为训练神经网络的规范，因此从业者注意到在某些情况下，例如对于对象识别或机器翻译，它们无法收敛到最佳，不如 Momentum。</p>

  <p>Reddi 等人正式解决了这个问题，指出过去平方梯度的指数移动平均值是自适应学习率方法的泛化行为不佳的原因之一。回想一下，引入指数平均值的动机很充分：应防止学习速度随着训练的进行而变得无穷小，而这是Adagrad 算法的关键缺陷。但是，在其他情况下，这种对梯度的短期记忆成为一个障碍。</p>

  <p>在 Adam 收敛到次优解的环境中，已经观察到一些小型批次提供了较大且信息丰富的梯度，但是由于这些小型批次很少发生，因此指数平均会降低其影响，从而导致较差的收敛性。作者提供了一个简单的凸优化问题的示例，其中 Adam 可以观察到相同的行为。为了解决此问题，作者提出了一种新算法 AMSGrad，该算法使用过去的平方梯度 $v_t$ 的最大值而不是指数平均值来更新参数。$v_t$ 的定义与上面的 Adam 相同：
<script type="math/tex">v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2</script>
现在，我们直接使用以前的 $v_{t-1}$（如果它大于当前的 $v_t$），而不是直接使用 $v_t$（或其偏差校正版本 $\hat v_t$）：
<script type="math/tex">\hat v_t = max(\hat v_{t-1}, v_t)</script>
这样，AMSGrad 的步长不会增加，从而避免了Adam 遇到的问题。为简单起见，作者还删除了我们在 Adam 中看到的去偏差步骤。可以看到完整的没有经过偏差校正的估计的 AMSGrad 更新：
<script type="math/tex">m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t \\
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 \\
\hat v_t = max(\hat v_{t-1}, v_t) \\
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon} m_t</script></p>
</blockquote>

<blockquote>
  <p>作者观察到在小型数据集和CIFAR-10上，与Adam相比，性能有所提高。但是，其他实验显示出与Adam相似或更差的性能。在实践中，AMSGrad是否能够始终胜过Adam，还有待观察。</p>
</blockquote>

<h3 id="使用哪个优化算法">使用哪个优化算法？</h3>

<blockquote>
  <p>如果输入数据稀疏，可以使用一种自适应学习率方法来获得最佳结果。另一个好处是，您无需调整学习率，但可以使用默认值获得最佳结果。</p>

  <p>总而言之，RMSprop 是 Adagrad 的扩展，用于处理其学习率从根本上降低的问题。它与 Adadelta 相同，除了 Adadelta 在分子更新规则中使用参数更新的 RMS。最后，Adam 为 RMSprop 添加了偏差校正和动量。Kingma等人表明，随着梯度变得稀疏，它的偏差校正有助于 Adam 在优化结束时略胜于 RMSprop。就目前而言，Adam 可能是最好的整体选择。</p>
</blockquote>

<h2 id="优化-sgd-的其他策略">优化 SGD 的其他策略</h2>

<blockquote>
  <p>最后，我们介绍了可以与前面提到的任何算法一起使用的其他策略，以进一步提高SGD的性能。</p>
</blockquote>

<h3 id="shuffling-和课程学习">Shuffling 和课程学习</h3>

<blockquote>
  <p>通常，我们希望避免以有意义的顺序向我们的模型提供训练示例，因为这可能会使优化算法产生偏差。因此，在每个 epoch 之后将训练数据 shuffling 通常是一个好主意。</p>

  <p>另一方面，在某些情况下，我们旨在解决日益棘手的问题，以有意义的顺序提供训练样本实际上可能会导致性能提高和更好的融合。建立这种有意义的顺序的方法称为课程学习。</p>

  <p>Zaremba 和 Sutskever 只能训练 LSTM 来使用课程学习评估简单的程序，并且表明联合或混合策略比单纯的策略更好，后者通过增加难度来对示例进行排序。</p>
</blockquote>

<h3 id="batch-normalization">Batch normalization</h3>

<blockquote>
  <p>为了促进学习，我们通常通过使用零均值和单位方差初始化参数的初始值来对其进行归一化。随着训练的进行以及我们在不同程度上更新参数，我们将失去这种标准化，这会减慢训练速度，并随着网络变得更深而扩大变化。</p>

  <p>批量归一化为每个小批量重新建立这些归一化，并且更改也通过操作反向传播。通过将归一化作为模型体系结构的一部分，我们可以使用较高的学习率，而对初始化参数的关注较少。批处理规范化还可以充当正则化器，从而减少（有时甚至消除）对 Dropout 的需求。</p>
</blockquote>

<h3 id="early-stopping">Early stopping</h3>

<blockquote>
  <p>根据 Geoff Hinton 的说法：“尽早停止是美丽的免费午餐”（NIPS 2015教程幻灯片，幻灯片63）。
因此，您应该始终在训练过程中监视验证集中的错误，如果验证错误没有得到足够的改善，则应停止（有耐心）。</p>
</blockquote>

<h3 id="gradient-noise">Gradient noise</h3>

<blockquote>
  <p>Neelakantan等人将噪声遵循高斯分布 $N(0, \sigma_t^2)$ 到每个梯度更新：
<script type="math/tex">g_{t,i} = g_{t,i} + N(0, \sigma_t^2)</script>
他们根据以下 schedule 对方差进行退火：
<script type="math/tex">\sigma_t^2 = \frac{\eta}{(1+t)^\gamma}</script>
他们表明，添加这种噪声可使网络对不良的初始化更加健壮，并有助于训练特别深而复杂的网络。他们怀疑增加的噪声使模型有更多的机会逃脱并找到新的局部极小值，这对于更深层的模型而言更为常见。</p>
</blockquote>

<h2 id="ref">Ref</h2>

<blockquote>
  <p><a href="https://ruder.io/optimizing-gradient-descent/index.html#whichoptimizertouse">An overview of gradient descent optimization algorithms</a></p>

  <p><a href="http://blog.csdn.net/google19890102/article/details/69942970">（中文版）An overview of gradient descent optimization algorithms</a></p>
</blockquote>

  </div>
  
</div>
<footer class="footer">
  <span>Copyright © TMaize</span>
  <span>Theme By</span>
  <a href="https://github.com/TMaize/tmaize-blog">TMaize</a>
</footer>
<div id="to-top">
  <span></span>
  <span></span>
</div>
<script type="text/javascript" src="/static/js/blog.js?t=20210622203029"></script>
<script type="text/javascript" src="/static/js/search.js?t=20210622203029"></script>
<!-- 点击页面文字冒出特效 -->
<script>
;(function(){
  var textArr = ['富强', '民主', '文明', '和谐', '自由', '平等', '公正', '法治', '爱国', '敬业', '诚信', '友善']
  window.blog.initClickEffect(textArr)
})()
</script>

<!-- 腾讯MTA移动分析 -->
<script>
  var _mtac = {performanceMonitor: 1, senseQuery: 1}
  ;(function() {
    if (window.location.hostname == '127.0.0.1') {
      return
    }
    var mta = document.createElement('script')
    mta.src = '//pingjs.qq.com/h5/stats.js?v2.0.4'
    mta.setAttribute('name', 'MTAH5')
    mta.setAttribute('sid', '500581966')
    mta.setAttribute('cid', '500581972')
    var s = document.getElementsByTagName('script')[0]
    s.parentNode.insertBefore(mta, s)
  })()
</script>

<!-- 百度自动推送 -->
<script>
  ;(function () {
    if (window.location.hostname == '127.0.0.1') {
      return
    }
    var bp = document.createElement('script')
    var curProtocol = window.location.protocol.split(':')[0]
    if (curProtocol === 'https') {
      bp.src = 'https://zz.bdstatic.com/linksubmit/push.js'
    } else {
      bp.src = 'http://push.zhanzhang.baidu.com/push.js'
    }
    var s = document.getElementsByTagName('script')[0]
    s.parentNode.insertBefore(bp, s)
  })()
</script>

<!-- MathJax数学公式支持 -->
<style>
  .has-jax {
    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
    background-color: transparent !important;
    line-height: normal !important;
    word-break: normal !important;
    padding: 0 !important;
    margin: 0 !important;
  }
  .has-jax * {
    outline: 0;
  }
</style>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    showProcessingMessages: false,
    messageStyle: "none",
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'a']
    },
    "HTML-CSS": {
      showMathMenu: false
    }
  });
  // 父级元素添加类名，便于css控制
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax();
    var i = 0;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
></script>


</body>
</html>
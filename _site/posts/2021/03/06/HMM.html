<!DOCTYPE html>
<html>
<head>
  <title>隐马尔可夫模型-EmiyaCC Blog</title>
  <meta charset="utf-8" />
  <meta http-equiv="content-language" content="zh-CN" />
  <meta name="theme-color" content="#ffffff" />
  <meta name="supported-color-schemes" content="light dark">
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta name="applicable-device" content="pc,mobile">
  <meta name="google-site-verification" content="ckhUaoa05QCmWoE1FafzTBcqYI4yBOy-UJKopXDS18M" />
  <meta name="author" content="EmiyaCC" />
  <meta name="description" content="隐马尔可夫模型"/>
  <meta name="keywords" content="EmiyaCC,机器学习"/>
  <link rel="icon" href="/static/img/favicon.ico" />
  <link rel="apple-touch-icon" href="/static/img/logo.png" />
  <link rel="stylesheet" href="/static/css/common.css?t=20210622203029">
  <link rel="stylesheet" href="/static/css/theme-dark.css?t=20210622203029">
  <link rel="stylesheet" href="/static/css/post.css?t=20210622203029">
  <link rel="stylesheet" href="/static/css/code-dark.css?t=20210622203029">
  <link rel="stylesheet" href="/static/css/code-light.css?t=20210622203029">
  <script>
    window.blog = {
      baseurl:"",
      buildAt:"20210622203029",
      darkTheme: false,
      setDarkTheme: function (dark) {
        this.darkTheme = Boolean(dark);
        document.documentElement.className = this.darkTheme ? 'dark': '';
        document.querySelector('meta[name=theme-color]').setAttribute('content', this.darkTheme ? '#2D2E32': '#FFFFFF');
      }
    }
    if (sessionStorage.darkTheme !== undefined) {
      blog.setDarkTheme(sessionStorage.darkTheme === 'true'); // 记忆值，单个窗口内有效
    } else {
      blog.setDarkTheme(window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches); // 跟随系统
    }
    if (window.matchMedia) {
      var media = window.matchMedia('(prefers-color-scheme: dark)');
      media.addListener(function (ev) {
        blog.setDarkTheme(ev.currentTarget.matches);
        sessionStorage.removeItem('darkTheme');
      });
    }
  </script>
</head>
<body ondragstart="return false;">
<header class="header">
  <img class="logo" src="/static/img/logo.jpg" alt="logo"/>
  <nav class="menu">
    <a href="/" class="hover-underline">首页</a>
    <a href="/pages/categories.html" class="hover-underline">归类</a>
    <a href="/pages/search.html" class="hover-underline">搜索</a>
    <a href="/pages/links.html" class="hover-underline">友链</a>
    <a href="/pages/about.html" class="hover-underline">关于</a>
    </nav>
</header>
<div class="page page-post">
  <h1 class="title" id="隐马尔可夫模型">隐马尔可夫模型</h1>
  
  <div class="subtitle">EmiyaCC 于 2021-03-06 发布</div>
  
  <div class="post">
    <div class="toc">
      <ul><li><a href="#隐马尔可夫模型hmm">隐马尔可夫模型（HMM）</a><ul><li><a href="#hmm-的基本概念">HMM 的基本概念</a></li><li><a href="#概率计算算法">概率计算算法</a><ul><li><a href="#直接计算法实际不可行">直接计算法（实际不可行）</a></li><li><a href="#前向算法">前向算法</a></li><li><a href="#后向算法">后向算法</a></li><li><a href="#一些概率与期望的计算">一些概率与期望的计算</a></li></ul></li><li><a href="#学习算法">学习算法</a><ul><li><a href="#监督学习方法">监督学习方法</a></li><li><a href="#em-算法">EM 算法</a></li></ul></li><li><a href="#预测算法">预测算法</a><ul><li><a href="#近似算法">近似算法</a></li><li><a href="#维特比算法viterbi-algorithm">维特比算法（Viterbi algorithm）</a></li></ul></li></ul></li></ul>

    </div>
    <h1 id="隐马尔可夫模型hmm">隐马尔可夫模型（HMM）</h1>

<blockquote>
  <p>本文摘抄自《统计学习方法》</p>

  <p>隐马尔可夫模型（Hidden Markov Model, HMM）是可用于标注问题的统计学习模型，描述由隐藏的马尔科夫链随机生成观测序列的过程，属于生成模型。</p>
</blockquote>

<h2 id="hmm-的基本概念">HMM 的基本概念</h2>

<blockquote>
  <p>HMM 是关于时序的概率模型，描述由一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测从而产生观测随机序列的过程。</p>

  <p>隐藏的马尔科夫链随机生成的状态的序列，称为状态序列（state sequence）；每个生成一个观测，而由此产生的观测的随机序列，称为观测序列（observation sequence）。序列的每一个位置又可以看作一个时刻。</p>
</blockquote>

<blockquote>
  <p>HMM 由初始概率分布、状态转移概率分布和观测概率分布，HMM 的形式定义如下：</p>

  <ul>
    <li>设 $Q$ 是所有可能的状态的集合，$V$ 是所有可能的观测的集合：
<script type="math/tex">Q = \{q_1, q_2, ..., q_N\}, ~~~~ V = \{v_1, v_2, ..., v_M\}</script>
      <blockquote>
        <p>其中，$N$ 是可能的状态数，$M$ 是可能的观测数</p>
      </blockquote>
    </li>
    <li>
      <p>$I$ 是长度为 $T$ 的状态序列，$O$ 是对应的观测序列：
<script type="math/tex">I = (i_1, i_2, ..., i_T), ~~~~ O = (o_1, o_2, ..., o_T)</script></p>
    </li>
    <li>$A$ 是状态转移概率矩阵：
<script type="math/tex">A = [a_{i,j}]_{N \times N} \\
a_{i,j} = P(i_{t+1} = q_j | i_t = q_i),~~~~i = 1, 2, ..., N; j = 1, 2, ..., N</script>
      <blockquote>
        <p>其中，$a_{i,j}$ 是在时刻 $t$ 处于状态 $q_i$ 的条件下在时刻 $t+1$ 转移到状态 $q_j$ 的概率。</p>
      </blockquote>
    </li>
    <li>$B$ 是观测概率矩阵：
<script type="math/tex">B = [b_j(k)]_{N \times M} \\
b_j(k) = P(o_t = v_k | i_t = q_j), ~~~~k = 1, 2, ..., M; j = 1, 2, ..., N</script>
      <blockquote>
        <p>其中，$b_j(k)$ 是在时刻 $t$ 处于状态 $q_j$ 的条件下生成观测 $v_k$ 的概率。</p>
      </blockquote>
    </li>
    <li>$\pi$ 是初始状态概率向量：
<script type="math/tex">\pi = (\pi_i) \\
\pi_i = P(i_1 = q_i), ~~~~i = 1, 2, ..., N</script>
      <blockquote>
        <p>其中，$\pi_i$ 是时刻 $t=1$ 处于状态 $q_i$ 的概率。</p>
      </blockquote>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p>HMM 由初始状态概率向量 $\pi$ 、状态转移概率矩阵 $A$ 和观测概率矩阵 $B$ 决定。符号表示为：
<script type="math/tex">\lambda = (A, B, \pi)</script>
<strong>$A, B, \pi$ 称为 HMM 的三要素</strong>。</p>

  <p>由定义可知，<strong>HMM 作了两个基本假设</strong>：</p>

  <ul>
    <li><strong>齐次马尔可夫性假设</strong>：当前时刻的状态值，仅依赖于前一时刻的状态值，而不依赖于更早时刻的状态值（马尔可夫性），也与时刻无关（齐次性；即所有时刻共享一个状态转移矩阵）。</li>
    <li><strong>观测独立性假设</strong>：当前时刻的观察值，仅依赖于当前时刻的状态值。</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>HMM 的三个基本问题</strong>:</p>

  <ul>
    <li>
      <table>
        <tbody>
          <tr>
            <td><strong>概率计算问题</strong>：给定模型 $\lambda = (A, B, \pi)$ 和观测序列 $O = (o_1, o_2, …, o_T)$，计算在模型 $\lambda$ 下观测序列 $O$ 出现的概率 $P(O</td>
            <td>\lambda)$</td>
          </tr>
        </tbody>
      </table>
    </li>
    <li>
      <table>
        <tbody>
          <tr>
            <td><strong>学习问题</strong>：已知观测序列 $O=(o_1, o_2, …, o_T)$，估计模型 $\lambda = (A, B, \pi)$ 参数，使得在该模型下观测序列概率 $P(O</td>
            <td>\lambda)$ 最大，即用极大似然估计的方法估计参数</td>
          </tr>
        </tbody>
      </table>
    </li>
    <li>
      <table>
        <tbody>
          <tr>
            <td><strong>预测问题</strong>：也称为解码问题。已知模型 $\lambda=(A, B, \pi)$ 和观测序列 $O=(o_1, o_2, …, o_T)$，求对给定观测序列条件概率 $P(I</td>
            <td>O)$ 最大的状态序列 $I = (i_1, i_2, …, i_T)$，即给定观测序列，求最有可能的对应的状态序列</td>
          </tr>
        </tbody>
      </table>
    </li>
  </ul>
</blockquote>

<h2 id="概率计算算法">概率计算算法</h2>

<blockquote>
  <table>
    <tbody>
      <tr>
        <td>给定模型 $\lambda = (A, B, \pi)$ 和观测序列 $O = (o_1, o_2, …, o_T)$，计算在模型 $\lambda$ 下观测序列 $O$ 出现的概率 $P(O</td>
        <td>\lambda)$</td>
      </tr>
    </tbody>
  </table>
</blockquote>

<h3 id="直接计算法实际不可行">直接计算法（实际不可行）</h3>

<blockquote>
  <table>
    <tbody>
      <tr>
        <td>通过列举所有可能的长度为 $T$ 的状态序列 $I=(i_1, i_2, …, i_T)$，求各个状态序列 $I$ 与观测序列 $O=(o_1, o_2, …, o_T)$ 的联合概率 $P(O,I</td>
        <td>\lambda)$，然后对所有可能的状态序列求和，得到 $P(O</td>
        <td>\lambda)$</td>
      </tr>
    </tbody>
  </table>

  <p>状态序列 $I=(i_1, i_2, …, i_T)$ 的概率是：
<script type="math/tex">P(I|\lambda) = \pi_{i_1}a_{i_1i_2}a_{i_2i_3}...a_{i_{T-1}i_{T}}</script>
对固定的状态序列 $I=(i_1, i_2, …, i_T)$，观测序列 $O=(o_1, o_2, …, o_T)$ 的概率是：
<script type="math/tex">P(O|I,\lambda) = b_{i_1}(o_1)b_{i_2}(o_2)...b_{i_T}(o_T)</script>
$O$ 和 $I$ 同时出现的联合概率是：
<script type="math/tex">% <![CDATA[
\begin{align}
P(O,I|\lambda) &= P(O|I,\lambda)P(I|\lambda) \\
& = \pi_{i_1} b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2)...a_{i_{T-1}i_{T}}b_{i_T}(o_T)
\end{align} %]]></script>
然后对所有可能的状态序列 $I$ 求和，得到观测序列 $O$ 的概率 $P(O|\lambda)$，即：
<script type="math/tex">% <![CDATA[
\begin{align}
P(O|\lambda) &= \sum_I P(O|I,\lambda)P(I|\lambda) \\
& = \sum_{i_1,i_2, ..., i_T} \pi_{i_1} b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2)...a_{i_{T-1}i_{T}}b_{i_T}(o_T)
\end{align} %]]></script>
但是上式计算量大（$O(TN^T)$），故可不行</p>
</blockquote>

<h3 id="前向算法">前向算法</h3>

<blockquote>
  <p>前向概率：给定 HMM $\lambda$，定义到时刻 $t$ 部分观测序列为 $o_1, o_2, …, o_t$ 且状态为 $q_i$ 的概率为前向概率，记作：
<script type="math/tex">\alpha_t(i) = P(o_1, o_2, ..., o_t, i_t = q_i|\lambda)</script></p>
</blockquote>

<blockquote>
  <p>输入：HMM $\lambda$，观测序列 $O$
输出：观测序列概率 $P(O|\lambda)$</p>

  <ol>
    <li>初值</li>
  </ol>

  <script type="math/tex; mode=display">\alpha_1(i) = \pi_ib_i(o_1), ~~~~i = 1, 2, ..., N</script>

  <ol>
    <li>
      <p>递推，对 $t = 1, 2, …, T-1$
<script type="math/tex">\alpha_{t+1}(i)=[\sum_{j=1}^N \alpha_t(j)a_{ji}]b_i(o_{t+1}), ~~~~i = 1, 2, ..., N</script></p>
    </li>
    <li>
      <p>终止
<script type="math/tex">p(O|\lambda) = \sum_{i=1}^N \alpha_T(i)</script></p>
    </li>
  </ol>
</blockquote>

<h3 id="后向算法">后向算法</h3>

<blockquote>
  <p>给定 HMM $\lambda$，定义在时刻 $t$ 状态为 $q_i$ 的条件下，从 $t+1$ 到 $T$ 的部分观测序列为 $o_{t+1}, o_{t+2}, … , o_T$ 的概率为后向概率，记作：
<script type="math/tex">\beta_t(i) = P(o_{t+1}, o_{t+2}, ..., o_T|i_t=q_i, \lambda)</script></p>
</blockquote>

<blockquote>
  <p>输入：HMM $\lambda$，观测序列 $O$
输出：观测序列概率 $P(O|\lambda)$</p>

  <ol>
    <li>
      <p>初值
<script type="math/tex">\beta_T(i) = 1, ~~~~i = 1, 2, ..., N</script></p>
    </li>
    <li>递推，对 $t = T-1, T-2, …, 1$
<script type="math/tex">\beta_{t}(i)=\sum_{j=1}^N a_{ij}b_j(o_{t+1})\beta_{t+1}(j), ~~~~i = 1, 2, ..., N</script></li>
    <li>终止</li>
  </ol>

  <script type="math/tex; mode=display">p(O|\lambda) = \sum_{i=1}^N \pi_ib_i(o_1)\beta_1(i)</script>
</blockquote>

<h3 id="一些概率与期望的计算">一些概率与期望的计算</h3>

<blockquote>
  <p>todo</p>
</blockquote>

<h2 id="学习算法">学习算法</h2>

<h3 id="监督学习方法">监督学习方法</h3>

<blockquote>
  <p>todo</p>
</blockquote>

<h3 id="em-算法">EM 算法</h3>

<blockquote>
  <p>todo</p>
</blockquote>

<h2 id="预测算法">预测算法</h2>

<blockquote>
  <table>
    <tbody>
      <tr>
        <td>已知模型 $\lambda=(A, B, \pi)$ 和观测序列 $O=(o_1, o_2, …, o_T)$，求对给定观测序列条件概率 $P(I</td>
        <td>O)$ 最大的状态序列 $I = (i_1, i_2, …, i_T)$，即给定观测序列，求最有可能的对应的状态序列</td>
      </tr>
    </tbody>
  </table>
</blockquote>

<h3 id="近似算法">近似算法</h3>

<blockquote>
  <p>近似算法的思想是，在每个时刻 $t$ 选择在时刻最有可能出现的状态 $i_t^<em>$，从而得到一个状态序列 $I^</em>=(i_1^<em>, i_2^</em>, …, i_T^*)$，将它作为预测的结果</p>
</blockquote>

<blockquote>
  <p>给定 HMM $\lambda$ 和观测序列 $O$，在时刻 $t$ 处于状态 $q_i$ 的概率 $\gamma_t(i)$ 是
<script type="math/tex">\gamma_t(i) = \frac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)} = \frac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N \alpha_t(j)\beta_t(j)}</script>
在每一时刻 $t$ 最有可能的状态 $i_t^<em>$ 是
<script type="math/tex">i_t^* = \arg \max_{1\leqslant i \leqslant N}[\gamma_t(i)], ~~~~t= 1, 2, ..., T</script>
从而得到状态序列 $I^</em>=(i_1^<em>,i_2^</em>, …, i_T^*)$</p>
</blockquote>

<blockquote>
  <p>优点是计算简单，缺点是不能保证预测的状态序列整体是最有可能的状态序列，因为预测的状态序列有可能有实际上不发生的部分（状态转移概率为0，即对某些 $i, j$  有 $a_{ij} = 0$）。</p>
</blockquote>

<h3 id="维特比算法viterbi-algorithm">维特比算法（Viterbi algorithm）</h3>

<blockquote>
  <p><a href="https://www.zhihu.com/question/20136144/answer/763021768">通俗解释 Viterbi algorithm</a></p>
</blockquote>

<blockquote>
  <p>维特比算法实际是用动态规划解 HMM 模型的预测问题，即用动态规划求概率最大路径（最优路径），这时一条路径对应着一个状态序列。</p>

  <p>根据动态规划原理，最优路径具有这样特性：如果最优路径在时刻 $t$ 通过结点 $i_t^<em>$，那么这一路径从结点 $i_t^</em>$ 到终点 $i_T^<em>$ 的部分路径，对于从 $i_t^</em>$ 到 $i_T^<em>$ 的所有可能的部分路径来说，必然是最优的。所以，我们只需从时刻 $t=1$ 开始，递推的计算在时刻 $t$ 状态为 $i$ 的各条部分路径的最大概率，直至得到时刻 $t=T$ 状态为 $i$ 的各条路径的最大概率。
时刻 $t=T$ 状态的最大概率即为最优路径的概率 $P^</em>$，最优路径的终结点 $i_T^<em>$ 也同时得到。之后，为了找出最优路径的各个结点，从终结点 $i_T^</em>$ 开始，由后往前逐步求得结点 $i_{T-1}^<em>, …, i_1^</em>$，得到最优路径 $I^* = (i_1^<em>, i_2^</em>, …, i_T^*)$。</p>
</blockquote>

<blockquote>
  <p>首先导入两个变量 $\delta$ 和 $\psi$</p>

  <p>定义在时刻 $t$ 状态为 $i$ 的所有单个路径 $(i_1, i_2, …, i_t)$ 中概率最大值为：
<script type="math/tex">\delta_t(i) = \max_{i_1, i_2, ..., i_{t-1}} P(i_t=i, i_{t-1}, ..., i_1, o_t, ..., o_1|\lambda), ~~~~i = 1, 2, ..., N</script>
由定义可得变量 $\delta$ 的递推公式：
<script type="math/tex">% <![CDATA[
\begin{align}
\delta_{t+1}(i) &= \max_{i_1, i_2, ..., i_t} P(i_{t+1}=i, i_t, ..., i_1, o_{t+1}, ..., o_1|\lambda), ~~~~i=1,2,...,N \\
&= \max_{1 \leqslant j \leqslant N}[\delta_t(j)a_{ji}]b_i(o_{t+1}), ~~~~i=1,2,...,N;t=1,2,...,T-1
\end{align} %]]></script>
定义在时刻 $t$ 的状态为 $i$ 的所有单个路径 $(i_1, i_2, …, i_{t-1}, i)$ 中概率最大的路径的第 $t-1$ 个结点为
<script type="math/tex">\psi_t(i) = \arg \max_{1 \leqslant j \leqslant N}[\delta_{t-1}(j)a_{ji}], ~~~~i=1,2,...,N</script></p>
</blockquote>

<blockquote>
  <p>输入：模型 $\lambda=(A,B,\pi)$ 和观测 $O=(o_1, o_2, …, o_T)$
输出：最优路径 $I^<em>=(i_1^</em>,i_2^<em>,…,i_T^</em>)$</p>

  <ol>
    <li>
      <p>初始化
<script type="math/tex">\delta_1(i) = \pi_ib_i(o_1), ~~~~i = 1,2,...,N \\
\psi_1(i) = 0, ~~~~i = 1, 2, ..., N</script></p>
    </li>
    <li>
      <p>递推，对 $t=2,3,…,T$
<script type="math/tex">\delta_t(i) = \max_{1 \leqslant j \leqslant N}[\delta_{t-1}(j)a_{ji}]b_i(o_t), ~~~~i = 1,2,...,N \\
\psi_t(i) = \arg \max_{1 \leqslant j \leqslant N}[\delta_{t-1}(j)a_{ji}], ~~~~i = 1, 2, ..., N</script></p>
    </li>
    <li>
      <p>终止
<script type="math/tex">p^* = \max_{1 \leqslant i \leqslant N} \delta_T(i) \\ 
i_T^* = \arg \max_{1 \leqslant i \leqslant N} [\delta_T(i)]</script></p>
    </li>
    <li>
      <p>最优路径回溯，对 $t=T-1,T-2, …, 1$
<script type="math/tex">i_t^* = \psi_{t+1}(i_{t+1}^*)</script>
求得最优路径 $I^* = (i_1^<em>, i_2^</em>, …, i_T^*)$</p>
    </li>
  </ol>
</blockquote>


  </div>
  
</div>
<footer class="footer">
  <span>Copyright © TMaize</span>
  <span>Theme By</span>
  <a href="https://github.com/TMaize/tmaize-blog">TMaize</a>
</footer>
<div id="to-top">
  <span></span>
  <span></span>
</div>
<script type="text/javascript" src="/static/js/blog.js?t=20210622203029"></script>
<script type="text/javascript" src="/static/js/search.js?t=20210622203029"></script>
<!-- 点击页面文字冒出特效 -->
<script>
;(function(){
  var textArr = ['富强', '民主', '文明', '和谐', '自由', '平等', '公正', '法治', '爱国', '敬业', '诚信', '友善']
  window.blog.initClickEffect(textArr)
})()
</script>

<!-- 腾讯MTA移动分析 -->
<script>
  var _mtac = {performanceMonitor: 1, senseQuery: 1}
  ;(function() {
    if (window.location.hostname == '127.0.0.1') {
      return
    }
    var mta = document.createElement('script')
    mta.src = '//pingjs.qq.com/h5/stats.js?v2.0.4'
    mta.setAttribute('name', 'MTAH5')
    mta.setAttribute('sid', '500581966')
    mta.setAttribute('cid', '500581972')
    var s = document.getElementsByTagName('script')[0]
    s.parentNode.insertBefore(mta, s)
  })()
</script>

<!-- 百度自动推送 -->
<script>
  ;(function () {
    if (window.location.hostname == '127.0.0.1') {
      return
    }
    var bp = document.createElement('script')
    var curProtocol = window.location.protocol.split(':')[0]
    if (curProtocol === 'https') {
      bp.src = 'https://zz.bdstatic.com/linksubmit/push.js'
    } else {
      bp.src = 'http://push.zhanzhang.baidu.com/push.js'
    }
    var s = document.getElementsByTagName('script')[0]
    s.parentNode.insertBefore(bp, s)
  })()
</script>

<!-- MathJax数学公式支持 -->
<style>
  .has-jax {
    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
    background-color: transparent !important;
    line-height: normal !important;
    word-break: normal !important;
    padding: 0 !important;
    margin: 0 !important;
  }
  .has-jax * {
    outline: 0;
  }
</style>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    showProcessingMessages: false,
    messageStyle: "none",
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'a']
    },
    "HTML-CSS": {
      showMathMenu: false
    }
  });
  // 父级元素添加类名，便于css控制
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax();
    var i = 0;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
></script>


</body>
</html>
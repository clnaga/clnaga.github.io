<?xml version="1.0" encoding="utf-8"?>
<ul>
  <li>最近的梯度下降算法的更新概述[toc]对之前的总结和补充VanillaGradientDescent现代深度学习优化器的故事始于朴素梯度下降。朴素梯度下降遵循以下迭代，具有一定的学习速率参数$\eta$：其中loss是从整个训练数据集中随机抽取的、使用一定数量的样本计算得出的平均loss。对于批次梯度下降（或简称为梯度下降），在每次迭代中都使用整个训练数据集来计算损失。对于随机梯度下降（SGD），每次迭代绘制一个样本。在实践中，通常使用微型批处理，并且常见的微型批处理大小在64到2048之间。小批量梯度下降非常普遍，通常称为SGD。Momentum考虑两种情况，a）局部损失景观是平坦的山丘，b）局部损失景观是陡峭的山沟。在第一种情况下，梯度下降算法可能要花很长时间才能到达山顶，即使它显然沿相同方向行进。在第二种情况下，梯度下降算法可能会在陡峭的山沟壁之间来回弹跳而不会很快到达底部，如果可以对来回梯度进行平均以减小方差，那将是很好的。这是需要梯度累加或平均机制的两种常见解释，这导致了Momentum出现。Momentum是由$\beta$（通常等于0.9）参数化的过去梯度的指数移动平均值（exponentialmovingaverageofpastgradients），由以下算法给出：有多种实现方式见JamesMelvilleAdaGrad(AdaptiveGradient)AdaGrad受直觉启发，不经常更新的权重应该以比经常更新的权重更大的学习率来更新。基本上，如果权重很少得到大的梯度，则当它收到大的梯度时应该充分利用它。这是通过保持每个权重的平方梯度的累加总和并将学习率除以该累加总和来实现的。从AdaGrad开始，针对$\theta$的每个坐标$i$的SGD递归变为：其中$G_t\in\mathbb{R}^{p\timesp}$通常是过去梯度的平方之和的对角线预处理矩阵，而$\epsilon&gt;0$是一个小常数。注意在$G_t$上使用的平方根（也可以有效地使用0到1之间的其他幂），但是平方根是一个很好的起点。这通常有另外两个含义：a）对超参数不像Momentum那么敏感（某些模型一次训练可能要花费100,000美元！），b）这近似于对角线矩阵，并且是仅使用一阶矩信息对二阶距的估计。这些学习速率自适应算法可以理解为利用当前和过去的梯度信息来设计更好地近似损失函数的局部曲率的预处理矩阵。RMSprop但是，AdaGrad中平方梯度的累积只会增加，这意味着如果优化程序运行足够长的时间，则实际上后续更新太小。RMSprop（均方根反向传播）将每次累积的矩阵$G_t$替换为每次迭代计算的梯度均方根，其中$\beta_2$最初建议为0.9，良好的默认学习率为0.001。然后，RMSprop更新为：Adam如果我们为RMSprop增加动力该怎么办？这就是Adam。除了RMSprop之外，Adam还保留了过去梯度的指数衰减平均值：【另外一个博客说这边还要计算经过偏差校正的第一和第二矩估计值来抵消这些偏差】其中建议$\beta_1=0.9,\beta_2=0.999,学习率\eta=0.001$。当$\beta_1=0$时，观察到Adam等于RMSprop。我们再次提到要注意$E[g^2]_t$的平方根可以取别的值，并且0到1之间的其他幂已经被有效使用（有一种称为Padam的算法）。AMSGradAMSGrad的动机在于，Adam无法收敛于一个简单的优化问题。作者通过Adam证明中有关指数移动平均$E[g^2]_t$的技术细节来解决此问题。AMSGrad保留了$E[g^2]$的运行最大值，而不是指数移动平均值。参数化AMSGrad算法（$\eta=0,\beta_1&lt;1,\beta_2&lt;1$）:通常公认的是，AMSGrad在实践中并不比Adam更好。另外，没人真正知道AMSGrad代表什么。AdamW权重衰减（Weightdecay）是训练神经网络的一种技术，它试图使权重值保持较小。直觉是，权重过大往往会造成过拟合。这通常是通过在损失函数中添加一个项来实现的，该项是权重值的函数，这样，较大的权重将显着增加总损失。权重衰减的最流行形式是L2正则化，它惩罚权重的平方值，并且便于同时处理正负权重以及可微性。AdamW通过将权重衰减与梯度更新解耦，修改了Adam中权重衰减正则化的典型实现。特别是，通常使用以下修改实现Adam中的L2正则化，其中$w_t$是时间$t$的权重衰减率：而AdamW则将权重衰减项调整为出现在梯度更新中：事实证明，这在实践上有所作为，并且已在机器学习社区的某些部分采用。您会惊讶于一些小细节如何对性能产生显着影响！RefAnupdatedoverviewofrecentgradientdescentalgorithmsTobecontinue</li>
  <li>梯度下降优化算法总览[toc]优化指的是改变$\theta$以最小化或最大化某个函数$J(\theta)$的任务。我们通常以最小化$J(\theta)$指代大多数最优化问题。最大化可经由最小化算法最小化$-J(\theta)$来实现。我们把要最小化或最大化的函数称为目标函数（objectivefunction）或准则（criterion）。当我们对其进行最小化时，我们也把它称为代价函数（costfunction）、损失函数（lossfunction）或误差函数（errorfunction）。【花书】梯度下降是一种优化算法，其中，学习率$\eta$决定了我们到达（局部）最小值的步长梯度下降种类梯度下降根据计算目标函数的梯度所用的数据量不同，大体分为三类。根据数据量，我们可以在参数更新的准确性和执行更新所需的时间之间进行权衡BGD（批次梯度下降）公式：由于在每一次更新中，我们都需要计算整个数据集的梯度，所以BGD可能会非常缓慢，并且内存装不下的数据集很棘手。不可在线学习（需要一次得到整个数据集）。然后，我们以与梯度相反的方向更新参数，学习率决定了我们执行的更新量。对于凸面误差曲面，批梯度下降可以保证收敛到全局最小值，对于非凸面曲面，可以保证收敛到局部最小值。SGD（随机梯度下降）相较与BGD，SGD对每个训练样本$x^{(i)}$和标签$y^{(i)}$都做参数更新。【由于是做BN，都是一个batch一个batch的算，计算一个batch里的所有样本】公式：BGD对于大型数据集会有冗余计算，因为他会在每个参数更新之前重新计算相似样本的梯度。SGD通过一次执行一次更新的方式来消除这种冗余，因此它通常速度很快，也可以用于在线学习。SGD频繁执行更新且变化很大，这导致目标函数如下图所示，会剧烈波动当BGD收敛到参数的盆地的最小值时，SGD的波动一方面使它跳到新的并可能是更好的局部最小值，但另一方面，这也导致SGD会错过最低值（overshooting），使得SGD收敛到最小值会很困难。但是，已经表明，当我们缓慢降低学习率时，SGD会显示与BGD相同的收敛行为，几乎可以肯定地，对于非凸优化和凸优化，它们分别收敛到局部或全局最小值。MBGD（小批次梯度下降）MBGD是BGD和SGD的折中，每次更新小批量中的$n$个样本的梯度。公式：这样做1）减少了参数更新的方差，这可以使收敛更加稳定，2）可以利用深度学习库的高度优化的矩阵优化功能，快速的计算一个小批次数据的梯度。常见的小批次大小设置在50到256之间（随不同应用变化），训练神经网络时，通常选择小批量梯度下降算法，而当使用小批量时，通常也使用术语SGD。挑战但是，MBGD不能保证良好的收敛性，但是存在一些需要解决的问题：选择合适的学习率十分困难，学习率太小会导致收敛过于缓慢，学习率太大导致不容易收敛，并导致损失函数在最小值附近波动甚至发散；学习率schedules可以在训练过程中调整学习率比如说退火算法，即根据预定义的时间表或在各个时期之间的目标变化降到阈值以下时降低学习率。但是，这些计划和阈值必须预先定义，因此无法适应数据集的特征；此外，所有参数更新都使用同一学习率。如果我们的数据稀疏并且特征有非常不同的频率，那么我们可能不想所有的参数都更新相同的程度，而是对较少出现的特征进行更大的更更新；最小化神经网络常见的高度非凸误差函数的另一个关键挑战是避免陷入其众多次优局部最小值中。Dauphinetal.认为收敛困难实际上不是由局部极小值引起的，而是由鞍点（即一维向上倾斜而另一维向下倾斜的点）引起的。这些鞍点通常被相同误差的平稳段包围，这使得SGD很难逃脱，因为在所有维度上梯度都接近于零。梯度下降优化算法MomentumSGD很难在沟壑中前进，即在一个维度上，曲面的弯曲比另一个维度要陡得多，这在局部最优情况下很常见。在这种情况下SGD会在峡谷得山坡山震荡，犹豫不决得向局部最优方向前进，如下图。Momentum可以在相关方向加速SGD并抑制震荡，如下图。通过将过去时间步长得更新向量的分数$\gamma$与当前更新向量相加来实现。公式：其中，动量项$\gamma$通常设为0.9。需要注意的是一些实现交换方程式中的符号，如下：其他实现见JamesMelville比如，我们将球推下山坡，球在下坡时滚动时会积累动量，在途中速度会越来越快（如果存在空气阻力，即$\gamma$&lt;1，直到达到最终速度）。我们的参数更新也发生了同样的事情：动量项对于梯度指向相同方向的维增加，而对于梯度改变方向的维减少动量。结果，我们获得了更快的收敛并减少了振荡。NAG(NesterovAcceleratedGradient)然后令人不满的是让一个球从山上滚下来，会盲目的随着斜坡滚，我们希望这个球具有要往何处的概念，这样当山坡再次变高之前知道它应该减速。NAG完成了这种预见的功能【花书中解释是相当于加了一个校正向量】，我们先通过计算$\theta-\gammav_{t-1}$计算出参数下一个位置的近似值（离完整更新还缺少梯度），通过计算不是现在位置的参数$\theta$而是未来的位置参数$\theta$的梯度，从而达到有效率的前看（lookahead）。公式为：其中，动量项$\gamma$通常设为0.9Momentum首先计算当前梯度（图中的蓝色小矢量），然后在更新的累积梯度（蓝色矢量）的方向上发生较大的跃迁，而NAG首先在先前的累积梯度的方向上进行较大的跃迁（棕色矢量），测量梯度，然后进行校正（红色矢量），从而完成NAG更新（绿色矢量）。这种预期的更新可防止我们过快地进行，并导致响应速度增加，从而显着提高了RNN在许多任务上的性能。现在，我们能够使更新适应误差函数的斜率并依次提高SGD，我们还希望使更新适应每个单独的参数，以根据其重要性执行更大或更小的更新。另一种角度解释，这里使用另一种NAG的实现方程：对NAG原来的更新公式进行变换，得到这样的等效形式：可以看到这个NAG的等效形式与Momentum的区别在于，本次更新方向多加了一个$\gamma[g(\theta_t)-g(\theta_{t-1})]$，它的直观含义就很明显了：如果这次的梯度比上次的梯度变大了，那么有理由相信它会继续变大下去，那我就把预计要增大的部分提前加进来；如果相比上次变小了，也是类似的情况。这个多加上去的项不就是在近似目标函数的二阶导！所以NAG本质上是多考虑了目标函数的二阶导信息，怪不得可以加速收敛了！其实所谓“往前看”的说法，在牛顿法这样的二阶方法中也是经常提到的，比喻起来是说“往前看”，数学本质上则是利用了目标函数的二阶导信息。等价推导，NAG原始公式：两边同时减$\eta\gammav_{t+1}$有：可令：代入上式有：对$\hatv_{t+1}$展开可得：所以$\hatv_{t+1}-\gamma\hatv_t$有：证明成功，原作者太强了。ref:https://zhuanlan.zhihu.com/p/22810533AdagradAdagrad是一种基于梯度的优化算法，它可以使学习率适应参数，对与频繁出现的特征相关的参数执行较小的更新（即低学习率），对与不频繁出现的特征相关的参数执行较大的更新（即高学习率）。因此非常适合处理稀疏数据之前，我们一次对所有的参数$\theta$进行更新，因为每个参数$\theta_i$使用相同的学习率$\eta$。因为Adagrad在每个时间步长$t$对每个参数$\theta_i$使用不同的学习率，因此首先对显示Adagrad的每个参数更新，再将其向量化。为了简便起见，使用$g_t$表示时间步长$t$处的梯度，$g_{t,i}$表示时间步长$t$参数$\theta_i$的目标函数的偏导数：在SGD中，每个时间步长$t$处每个参数$\theta$的更新为：在Adagrad中，基于对$\theta_i$计算的过去梯度，针对每个参数$\theta_i$在每个时间步长$t$修改通用学习率$\eta$：其中，$G_t\in\mathbb{R}^{d\timesd}$，这是个对角矩阵，其中每个对角元素$i,i$是在时间步长$t$处$\theta_i$的梯度的平方和，$\epsilon$是一个平滑项（smoothingterm），避免分母为0（通常设置为$1e^{-8}$量级）。有趣的是，如果没有平方根运算，该算法的性能将大大降低由于$G_t$包括过去的沿对角线的所有参数$\theta$梯度的平方和，所有我们可以通过对$G_t$和$g_t$之间做矩阵向量点积$\odot$来向量化实现：Adagrad的主要好处之一是，它无需手动调整学习率，大多数实现使用默认的0.01Adagrad的主要弱点是分母中平方梯度的累加：由于每个加法项都是正数，所以累加和在训练期间不断增长。反过来，这导致学习率下降，并最终变得无限小，这时该算法不再能够获取其他知识。以下算法旨在解决此缺陷。AdadeltaAdadelta是Adagrad的扩展，旨在降低其激进的，单调降低的学习率。Adadelta不会累计所有过去的平方梯度，而是将累计过去的梯度的窗口限制为某个固定大小$w$。代替无效的存储过去平方梯度（pastsquaredgradients），将梯度之和递归定义为所有过去梯度梯度的衰减平均值（decayingaverage），在时间步长$t$处的移动平均值（runningaverage）$E[g^2]_t$仅取决与先前的平均值和当前梯度（分数$\gamma$相当于Momentum里的动量项）：我们将$\gamma$设置与动量项相似的值，约为0.9。为了清晰起见，先根据参数更新向量$\Delta\theta_t$来重写朴素SGD：因此，我们先前推导的Adagrad的参数更新向量采用以下形式：现在我们用过去梯度梯度上的衰减平均值（decayingaverage）代替对角矩阵$G_t$：由于分母只是梯度的均方差（RMS）误差准组，可以替换简写准则：作者注意到，此处更新的单位（以及SGD，Momentum或Adagrad中的单位）不匹配，即，更新应具有与参数相同的假设单位。为了实现这一点，他们首先定义了另一个指数衰减的平均值，这次不是平方梯度而是平方参数更新：由于$RMS[\Delta\theta]t$是未知的，因此我们使用参数更新的$RMS$对其进行近似，直到上一个时间步长为止。最终，用$RMS[\Delta\theta]{t-1}$代替先前的更新规则中的学习率$\eta$，得出Adadelta更新规则：所以使用Adadelta，我们甚至不需要设置默认的学习率，因为它已从更新规则中删除。RMSpropRMSprop是由GeoffHinton在他的Coursera课的第6e讲中提出的未公开的自适应学习率方法。RMSprop和Adadelta大约在同一时间提出，这是因为需要解决Adagrad的学习率急剧下降的问题。RMSprop实际上与我们上面得出的Adadelta的第一个更新向量相同：RMSprop也将学习率除以平方梯度的指数衰减平均值（exponentiallydecayingaverage）。Hinton建议将$\gamma$设置为0.9，学习率$\eta$的默认值是0.001。Adam(AdaptiveMomentEstimation)Adam是另一种计算每个参数的自适应学习率的方法。等价RMSprop+Momentum除了存储像Adadelta和RMSprop这样的过去平方梯度$v_t$的指数衰减平均值之外，Adam还保留了过去梯度$m_t$的指数衰减平均值，类似于Momentum。Momentum以看作是一个顺着斜坡滑下的球，而Adam的行为就像是一个带有摩擦的沉重的球，因此，它更喜欢在误差表面上保持平坦的最小值。我们分别计算过去梯度$m_t$和过去平方梯度$v_t$的衰减平均值，如下所示：$m_t$和$v_t$分别是梯度的第一矩（均值）和第二矩（无中心方差）的估计值。当$m_t$和$v_t$初始化为0的向量时，Adam的作者观察到它们偏向零，尤其是在初始时间步长，衰减率较小时（即β1和β2接近1）。他们通过计算经过偏差校正的第一和第二矩估计值来抵消这些偏差：然后，他们使用它们来更新参数，就像在Adadelta和RMSprop中所看到的那样，这将产生Adam更新规则：作者建议将$\beta_1$的默认值设置为0.9，将$\beta_2$的默认值设置为0.999，将$\epsilon$的默认值设置为$10^{-8}$。AdaMaxAdam的更新规则中，$v_t$与过去梯度（通过$v_{t-1}$）和当前梯度$|g_t|^2$的$l_2$范数成反比的缩放梯度：我们可以将此更新推广到$l_p$范数：大$p$值的范数通常在数值上变得不稳定，这就是为什么$l_1$和$l_2$范数在实践中最常见的原因。但是，$l_\infty$通常也表现出稳定的行为。因此，作者提出了AdaMax，并证明具有$l_\infty$的$v_t$收敛到以下更稳定的值。为了避免与Adam混淆，我们使用$u_t$表示无穷范数约束$v_t$：然后就可以将$u_t$代替$\sqrt{v_t}+\epsilon$插入Adam的更新方程中，得到AdaMax的更新规则：请注意，由于$u_t$依赖于$max$运算，因此不建议像Adam中的$m_t$和$v_t$那样偏向零，这就是为什么我们不需要计算$u_t$的偏差校正的原因。默认值是$\eta=0.002,\beta_1=0.9,\beta_2=0.999$。Nadam(Nesterov-acceleratedAdaptiveMomentEstimation)如之前所见，Adam可以看作是RMSprop和Momentum的组合：RMSprop贡献了过去平方梯度$v_t$的指数衰减平均值，而Momentum贡献了过去梯度$m_t$的指数衰减平均值。同时我们也看到NAG由于普通的Momentum。因此，Nadam结合了Adam和NAG。为了将NAG合并到Adam中，我们需要修改其动量项$m_t$。首先回顾Momentum的更新规则：其中$J$是我们的目标函数，$\gamma$是动量衰减项，$\eta$是我们的步长。将上面的第三个方程式扩展会得出：这再次证明了Momentum在前一个动量矢量的方向上迈出一步以及在当前梯度的方向上迈出一步。NAG允许我们在计算梯度之前通过用动量步长更新参数来在梯度方向上执行更精确的步长。因此，我们只需要修改梯度$g_t$即可得出NAG：Dozat建议以以下方式修改NAG：直接应用前瞻动量矢量（look-aheadmomentumvector）来更新当前参数，而不是用两此Momentum步骤（一次用于更新梯度$g_t$，第二次用于更新参数$\theta_{t+1}$）注意到，我们不再像上面的Momentum更新规则的公式那样使用先前的动量矢量$m_{t-1}$，而是现在使用当前的动量矢量$m_t$向前看。为了将Nesterov动量添加到Adam，我们可以类似地用当前动量矢量替换以前的动量矢量。首先，回想一下Adma更新规则如下（注意，我们不需要修改$\hatv_t$，所以此处省略$\hatv_t$的更新公式）：依次用$\hatm_t$和$m_t$的定义扩展第二个方程式，我们得到：注意到，$\frac{\beta_1m_{t-1}}{1-\beta_1^t}$只是前一时间步长的动量矢量的偏差校正估计，因此，我们可以将其替换为$m_{t-1}$：为简单起见，我们忽略了分母为$1-\beta_1^t$而不是$1-\beta_1^{t-1}$，因为无论如何我们将在下一步中替换分母。该方程式再次看起来与我们上面扩展的Momentum更新规则非常相似。现在，我们可以像以前一样添加Nesterov动量，只需用当前动量矢量$\hatm_{t-1}$的偏差校正后的估计值简单地替换前一个时间步$\hatm_t$的该偏差校正后的估计值即可，Nadam更新规则：AMSGrad由于自适应学习率方法已成为训练神经网络的规范，因此从业者注意到在某些情况下，例如对于对象识别或机器翻译，它们无法收敛到最佳，不如Momentum。Reddi等人正式解决了这个问题，指出过去平方梯度的指数移动平均值是自适应学习率方法的泛化行为不佳的原因之一。回想一下，引入指数平均值的动机很充分：应防止学习速度随着训练的进行而变得无穷小，而这是Adagrad算法的关键缺陷。但是，在其他情况下，这种对梯度的短期记忆成为一个障碍。在Adam收敛到次优解的环境中，已经观察到一些小型批次提供了较大且信息丰富的梯度，但是由于这些小型批次很少发生，因此指数平均会降低其影响，从而导致较差的收敛性。作者提供了一个简单的凸优化问题的示例，其中Adam可以观察到相同的行为。为了解决此问题，作者提出了一种新算法AMSGrad，该算法使用过去的平方梯度$v_t$的最大值而不是指数平均值来更新参数。$v_t$的定义与上面的Adam相同：现在，我们直接使用以前的$v_{t-1}$（如果它大于当前的$v_t$），而不是直接使用$v_t$（或其偏差校正版本$\hatv_t$）：这样，AMSGrad的步长不会增加，从而避免了Adam遇到的问题。为简单起见，作者还删除了我们在Adam中看到的去偏差步骤。可以看到完整的没有经过偏差校正的估计的AMSGrad更新：作者观察到在小型数据集和CIFAR-10上，与Adam相比，性能有所提高。但是，其他实验显示出与Adam相似或更差的性能。在实践中，AMSGrad是否能够始终胜过Adam，还有待观察。使用哪个优化算法？如果输入数据稀疏，可以使用一种自适应学习率方法来获得最佳结果。另一个好处是，您无需调整学习率，但可以使用默认值获得最佳结果。总而言之，RMSprop是Adagrad的扩展，用于处理其学习率从根本上降低的问题。它与Adadelta相同，除了Adadelta在分子更新规则中使用参数更新的RMS。最后，Adam为RMSprop添加了偏差校正和动量。Kingma等人表明，随着梯度变得稀疏，它的偏差校正有助于Adam在优化结束时略胜于RMSprop。就目前而言，Adam可能是最好的整体选择。优化SGD的其他策略最后，我们介绍了可以与前面提到的任何算法一起使用的其他策略，以进一步提高SGD的性能。Shuffling和课程学习通常，我们希望避免以有意义的顺序向我们的模型提供训练示例，因为这可能会使优化算法产生偏差。因此，在每个epoch之后将训练数据shuffling通常是一个好主意。另一方面，在某些情况下，我们旨在解决日益棘手的问题，以有意义的顺序提供训练样本实际上可能会导致性能提高和更好的融合。建立这种有意义的顺序的方法称为课程学习。Zaremba和Sutskever只能训练LSTM来使用课程学习评估简单的程序，并且表明联合或混合策略比单纯的策略更好，后者通过增加难度来对示例进行排序。Batchnormalization为了促进学习，我们通常通过使用零均值和单位方差初始化参数的初始值来对其进行归一化。随着训练的进行以及我们在不同程度上更新参数，我们将失去这种标准化，这会减慢训练速度，并随着网络变得更深而扩大变化。批量归一化为每个小批量重新建立这些归一化，并且更改也通过操作反向传播。通过将归一化作为模型体系结构的一部分，我们可以使用较高的学习率，而对初始化参数的关注较少。批处理规范化还可以充当正则化器，从而减少（有时甚至消除）对Dropout的需求。Earlystopping根据GeoffHinton的说法：“尽早停止是美丽的免费午餐”（NIPS2015教程幻灯片，幻灯片63）。因此，您应该始终在训练过程中监视验证集中的错误，如果验证错误没有得到足够的改善，则应停止（有耐心）。GradientnoiseNeelakantan等人将噪声遵循高斯分布$N(0,\sigma_t^2)$到每个梯度更新：他们根据以下schedule对方差进行退火：他们表明，添加这种噪声可使网络对不良的初始化更加健壮，并有助于训练特别深而复杂的网络。他们怀疑增加的噪声使模型有更多的机会逃脱并找到新的局部极小值，这对于更深层的模型而言更为常见。RefAnoverviewofgradientdescentoptimizationalgorithms（中文版）Anoverviewofgradientdescentoptimizationalgorithms</li>
  <li>标题这里是h1这里是h2这里是h3这里是h4这里是h5这里是h6#这里是h1##这里是h2###这里是h3####这里是h4#####这里是h5######这里是h6段落段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落一段落段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落二段落超链接TMaizeBlog[TMaizeBlog](http://blog.tmaize.net)引用这里是引用&gt;这里是引用常见字体样式斜体粗体删除线_斜体_**粗体**~~删除线~~列表无序列表1-1缩进2空格缩进2空格缩进2空格无序列表1-2无序列表1-3有序列表1-1缩进3空格缩进3空格缩进3空格有序列表1-2有序列表1-3-无序列表1-1缩进2空格-缩进2空格-缩进2空格-无序列表1-2-无序列表1-31.有序列表1-1缩进3空格1.缩进3空格2.缩进3空格2.有序列表1-23.有序列表1-3分割线---图片破事水滑稽![line](http://xx.com/xx.jpg)块级别图片![测试图片](001.jpg)代码行这是一段文字rm-rf/*这是一段文字这是一段文字`rm-rf/*`这是一段文字代码块blog.encodeHtml=function(html){varo=document.createElement('div')o.innerText=htmlvartemp=o.innerHTMLo=nullreturntemp}​```javascriptblog.encodeHtml=function(html){varo=document.createElement('div')o.innerText=htmlvartemp=o.innerHTMLo=nullreturntemp}```表格测试TablesAreCoolcol3isright-aligned$1600col2iscentered$12zebrastripesareneat$1​```md|Tables|Are|Cool||————-|:———–:|—–:||col3is|right-aligned|$1600||col2is|centered|$12||zebrastripes|areneat|$1|##数学公式需要在配置中开启这是一行话`\(\int_0^\infty\frac{x^3}{e^x-1}\,dx=\frac{\pi^4}{15}\)`这是一行话`\[\int_0^\infty\frac{x^3}{e^x-1}\,dx=\frac{\pi^4}{15}\]`##插入html&lt;divid="htmldemo"&gt;&lt;/div&gt;&lt;style&gt;#htmldemo{height:30px;width:30px;background-color:#00aa9a;animation-name:moveX;animation-duration:1s;animation-timing-function:linear;animation-iteration-count:infinite;animation-direction:alternate;animation-fill-mode:both;}@keyframesmoveX{0%{transform:translateX(0px);}100%{transform:translateX(100px);}}&lt;/style&gt;```html&lt;divid="htmldemo"&gt;&lt;/div&gt;&lt;style&gt;#htmldemo{height:30px;width:30px;background-color:#00aa9a;animation-name:moveX;animation-duration:1s;animation-timing-function:linear;animation-iteration-count:infinite;animation-direction:alternate;animation-fill-mode:both;}@keyframesmoveX{0%{transform:translateX(0px);}100%{transform:translateX(100px);}}&lt;/style&gt;插入iframe&lt;!--属性什么的不要错了，最好用双引号括住--&gt;&lt;!--网易云的iframe需要做些调整，调整如下--&gt;&lt;iframesrc="//music.163.com/outchain/player?type=2&amp;id=28445796&amp;auto=0&amp;height=66"frameborder="0"width="100%"height="86px"&gt;&lt;/iframe&gt;</li>
</ul>